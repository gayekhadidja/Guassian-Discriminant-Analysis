{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GDA Implementation.\n",
        "\n",
        "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
        "\n",
        "INSTRUCTION: Rename your notebook as: <br>\n",
        "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
        "\n",
        "Notes: \n",
        "* Do not use any built-in functions to complete a task;\n",
        "* Do not import additional libraries."
      ],
      "metadata": {
        "id": "g17Z46tmw2oZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "aT5nlL-QTKwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "def generate_data():\n",
        "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
        "                           n_informative=3, random_state=1, \n",
        "                           n_clusters_per_class=1)\n",
        "  \n",
        "  return x,y\n",
        "\n",
        "x,y= generate_data()\n",
        "print(x.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lL4Yq9Tbzn",
        "outputId": "b17c6232-f4c8-4128-c70e-e34dc4be85dc"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(x,y, train_size= 0.8):\n",
        "    # shuffle the data to randomize the train/test split\n",
        "    n = y.shape[0]\n",
        "    if y.ndim == 1:\n",
        "      y = y.reshape(-1,1)\n",
        "    data = np.hstack((x,y))\n",
        "    data_suffe = np.random.permutation(data)\n",
        "    X_train = data_suffe[:round(n*train_size),:-1]\n",
        "    y_train = data_suffe[:round(n*train_size):,-1]\n",
        "    X_test = data[round(n*train_size): ,:-1]\n",
        "    y_test = data[round(n*train_size):,-1]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "     "
      ],
      "metadata": {
        "id": "EUgiWLDhUAAK"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test= split_data(x,y, train_size= 0.8) # split your data into x_train, x_test, y_train, y_test\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2Akm_A_FcJ",
        "outputId": "bef0c702-079d-4052-e8d1-aa692e34e8cd"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 3) (800,) (200, 3) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def phi_function(y,k):\n",
        "\n",
        "  # we can use np.unique(y) to see our different class which the output will be array([0, 1])so we have class 0 and class 1\n",
        "  if k == 1 :\n",
        "    s = np.sum(y==1)\n",
        "    \n",
        "  else:\n",
        "    s= np.sum(y==0)\n",
        "  return s\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "_aZye42hvOQ9"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mu_function(x, y,k ):\n",
        "  n,d = x.shape\n",
        "  k = len(np.unique(y))\n",
        "  mu = np.zeros((k,d))\n",
        "  x1 = np.zeros((d,1))\n",
        "  s = 0 #number of example in our class 1 \n",
        "  for i in range(n):\n",
        "    if y[i]== 1:\n",
        "    \n",
        "      mu[1] += x[i,:]/phi_function(y,1)\n",
        "\n",
        "    else:\n",
        "      mu[0] += x[i,:]/phi_function(y,0)\n",
        "  return mu\n",
        "    "
      ],
      "metadata": {
        "id": "qCegGLLUw_Te"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_function(x, y,1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-r6QbaISBof",
        "outputId": "fc1ed015-57f2-4fa6-9505-32840a859f16"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.99515416,  1.04188282,  0.99941748],\n",
              "       [-1.01309105,  0.95696514, -0.93218425]])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def covariance(x ,mu):\n",
        "  n,d = x.shape\n",
        "  cov= np.zeros((d,d))\n",
        "  for i in range(d):\n",
        "    for j in range(d):\n",
        "      cov[i,j]= (1/n)*np.sum((x[:,i] - mu[i])*(x[:,j] - mu[j]).T)\n",
        "\n",
        "  return cov\n",
        "\n",
        "  # Easy way: cov= np.cov(x, rowvar=0) but do not use it. One can use it to assess his/her result.\n",
        " "
      ],
      "metadata": {
        "id": "FrJ7GfXBHNxD"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.cov(x,rowvar=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r87l4pu_QnmC",
        "outputId": "89e0584f-363a-4a38-8b44-0993b76180ca"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.84495325, 0.02790646, 1.00137533],\n",
              "       [0.02790646, 1.00170721, 0.05539176],\n",
              "       [1.00137533, 0.05539176, 1.74832   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covariance(x, np.mean(x, axis = 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fjwn3N_afao",
        "outputId": "162c174e-dbd7-46d4-9fc2-c9eb7b8a9af7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.84310829, 0.02787855, 1.00037396],\n",
              "       [0.02787855, 1.0007055 , 0.05533637],\n",
              "       [1.00037396, 0.05533637, 1.74657168]])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from _typeshed import NoneType\n",
        "class GDA:\n",
        "  def __init__(self):\n",
        "    ## set mu, phi and sigma to None\n",
        "    def _init_(self):\n",
        "      self.phi = None\n",
        "      self.sigma = None\n",
        "      self.mu = None\n",
        "  \n",
        "  def fit(self,x,y):\n",
        "    k= np.unique(y).shape[0] # Number of class.\n",
        "    d=  x.shape[1]#input dim\n",
        "    m=x.shape[0] # Number of examples.\n",
        "    \n",
        "    ## Initialize mu, phi and sigma\n",
        "    self.mu= np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
        "    self.sigma=  np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
        "    self.phi= np.zeros(d)# d-dimension\n",
        "\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "    for clas in range(k):\n",
        "      self.phi[clas] = np.sum(clas==y)/m\n",
        "      self.mu[clas] = np.mean(x[clas==y] , axis =0)\n",
        "      self.sigma[clas] = covariance(x[clas==y] ,self.mu[clas])\n",
        "      \n",
        "\n",
        "\n",
        "  def predict_proba(self,x):\n",
        "    from math import pi\n",
        "    # reshape or flatt x.\n",
        "    \n",
        "    d= x.shape[1]\n",
        "    k_class= self.mu.shape[0]# Number of classes we have in our case it's k = 2\n",
        "    p_x_y0 = np.zeros((x.shape[0],k_class))\n",
        "    for clas in range(k_class):\n",
        "     \n",
        "      a = 1/((2*pi)**(d/2))\n",
        "      detsig = np.linalg.det(self.sigma[clas])**(1/2)\n",
        "      inversig = np.linalg.inv(self.sigma[clas])\n",
        "      for i in range(x.shape[0]):\n",
        "\n",
        "        z= (x[i] -self.mu[clas])@inversig.T@(x[i]-self.mu[clas])\n",
        "\n",
        "      ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "        p_x_y0[i,clas] = (1/(a*detsig))* (np.exp((-(1/2)*z)))*self.phi[clas]\n",
        "    \n",
        "    return p_x_y0\n",
        "  def predict(self,x):\n",
        "    ypred = self.predict_proba(x)\n",
        "    ypreds = np.argmax(ypred, axis =1)\n",
        "    return ypreds\n",
        "    \n",
        "  def accuracy(self, y, ypreds):\n",
        "    acc = np.mean(y==ypreds)*100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "1ocKLDAfceF0"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= GDA()\n",
        "model.fit(X_train,y_train)\n",
        "#model.predict_proba(X_train)"
      ],
      "metadata": {
        "id": "l_qO0Yp1c3Is"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yproba= model.predict_proba(X_test)\n",
        "yproba"
      ],
      "metadata": {
        "id": "NKY1eojY1l4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9316da-f07d-4d59-bbd8-e29ac07779b8"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.95290894e+001, 5.32457306e-001],\n",
              "       [1.65251463e+001, 9.24384604e-005],\n",
              "       [1.89188504e+001, 1.29415709e-005],\n",
              "       [2.35759442e+001, 6.19838880e-002],\n",
              "       [3.29681374e-065, 1.00125123e+001],\n",
              "       [2.12342006e-022, 1.24155947e+000],\n",
              "       [7.26150949e-001, 3.88100845e-003],\n",
              "       [6.36819342e+000, 1.40361317e-005],\n",
              "       [5.81489844e+000, 1.31664466e-005],\n",
              "       [3.85232545e+000, 2.47746144e-002],\n",
              "       [3.64852220e-039, 7.46168360e-001],\n",
              "       [4.11287395e-001, 5.97733482e-002],\n",
              "       [2.92483887e-021, 8.62486589e+000],\n",
              "       [1.60220653e-003, 6.40397305e-001],\n",
              "       [7.21171240e-039, 1.07335383e+001],\n",
              "       [2.33437642e-080, 6.97059435e+000],\n",
              "       [6.23551225e+000, 1.62443807e-001],\n",
              "       [1.31651031e-001, 4.12261674e+000],\n",
              "       [1.45911323e-001, 1.17050533e-001],\n",
              "       [3.64537884e-006, 9.57753846e+000],\n",
              "       [1.29235621e+000, 1.23392948e-014],\n",
              "       [3.36704770e+001, 2.57427354e-002],\n",
              "       [2.92950904e-129, 1.73551185e+000],\n",
              "       [1.67965524e-024, 1.16677209e+001],\n",
              "       [2.62631555e+001, 1.39088546e-003],\n",
              "       [1.36543075e-025, 1.01717528e+001],\n",
              "       [5.93916462e+000, 2.88707471e-004],\n",
              "       [6.49789181e+000, 1.64961494e-001],\n",
              "       [3.87995701e+001, 5.12026876e-002],\n",
              "       [1.71661969e-012, 6.67477897e+000],\n",
              "       [6.32940826e+000, 1.19076073e-004],\n",
              "       [4.29078976e-023, 1.31739632e+001],\n",
              "       [4.11378859e+000, 2.71838540e-001],\n",
              "       [1.75218827e+001, 1.31944468e-002],\n",
              "       [7.56182666e+000, 7.54905824e-002],\n",
              "       [1.98297479e+001, 1.05706702e-001],\n",
              "       [1.01382916e+001, 4.42211333e-002],\n",
              "       [1.02081558e-152, 1.71134566e+000],\n",
              "       [1.11312990e-013, 2.01653973e+000],\n",
              "       [3.22259726e+000, 1.21843053e-001],\n",
              "       [6.06414730e+000, 3.36579628e-005],\n",
              "       [1.06737893e-024, 2.93435410e+000],\n",
              "       [8.72441767e-037, 2.75215420e+000],\n",
              "       [1.47408243e+001, 1.37123697e+000],\n",
              "       [2.78183431e+001, 5.37014764e-002],\n",
              "       [9.41293604e-059, 6.69332771e+000],\n",
              "       [3.07850915e+001, 8.30096597e-001],\n",
              "       [6.15944876e+000, 4.88820549e-004],\n",
              "       [1.02669905e+001, 1.89951038e+000],\n",
              "       [1.65183298e+000, 1.99258298e-011],\n",
              "       [1.67219008e+000, 2.39475241e-019],\n",
              "       [2.17483236e+001, 6.65285278e-002],\n",
              "       [9.80232231e+000, 1.35665940e+000],\n",
              "       [2.44766836e-008, 1.61126092e-001],\n",
              "       [3.48809431e-071, 2.00834423e+000],\n",
              "       [3.64832413e+000, 9.75326766e-003],\n",
              "       [1.97906107e-024, 8.74880009e+000],\n",
              "       [2.69365604e-012, 2.54243514e+000],\n",
              "       [1.57589100e+001, 6.38557418e-001],\n",
              "       [5.73037512e-002, 1.10750249e-001],\n",
              "       [1.15660937e+001, 2.99117363e-002],\n",
              "       [1.31080368e-073, 6.49616904e+000],\n",
              "       [3.48336732e-035, 3.31583344e+000],\n",
              "       [2.51455883e+001, 1.82661231e-002],\n",
              "       [2.36676167e+001, 2.28491034e+000],\n",
              "       [1.19820995e+001, 4.47094491e-002],\n",
              "       [2.29515006e-116, 2.72008733e+000],\n",
              "       [2.29370332e+001, 4.98525436e-006],\n",
              "       [5.53576812e-041, 1.08040447e+001],\n",
              "       [6.66741993e+000, 1.20302553e-007],\n",
              "       [2.87699761e-046, 7.20922641e+000],\n",
              "       [2.61082526e+000, 3.62627230e+000],\n",
              "       [1.25970144e-019, 1.36325989e+001],\n",
              "       [4.93421311e-033, 1.43033115e+000],\n",
              "       [3.04116468e-029, 2.05041216e+000],\n",
              "       [1.62266675e+001, 8.03470024e-002],\n",
              "       [3.26096629e-136, 2.46420543e+000],\n",
              "       [1.94254891e+000, 2.82813358e+000],\n",
              "       [3.02209424e+001, 1.35758314e-002],\n",
              "       [6.27844327e+000, 1.98562467e-003],\n",
              "       [1.95379587e-007, 8.72290665e+000],\n",
              "       [7.38360742e+000, 6.74755995e-002],\n",
              "       [2.50074627e-003, 8.49036904e-001],\n",
              "       [3.24038947e-016, 8.80451152e+000],\n",
              "       [5.51971614e+000, 2.13997567e-006],\n",
              "       [1.03761579e+001, 1.65668530e-002],\n",
              "       [9.92399364e-025, 4.15315872e+000],\n",
              "       [7.71308749e-050, 1.26894068e+001],\n",
              "       [5.05484035e+000, 2.07744410e-003],\n",
              "       [3.19146246e+001, 1.25019527e-001],\n",
              "       [4.77959208e+000, 5.63926617e-004],\n",
              "       [2.12664871e-036, 1.13802680e+001],\n",
              "       [1.13331624e-030, 8.85022007e+000],\n",
              "       [2.11812153e+001, 4.12894584e-001],\n",
              "       [5.41530041e-057, 1.91003235e+000],\n",
              "       [1.34855458e+000, 2.69251930e-001],\n",
              "       [7.00938511e-095, 4.26836206e+000],\n",
              "       [1.91327858e-013, 5.80277867e+000],\n",
              "       [2.64365209e-054, 1.01440385e+000],\n",
              "       [9.88772936e+000, 2.22681305e-008],\n",
              "       [2.01360309e-130, 2.64858147e+000],\n",
              "       [8.82703628e+000, 1.83745842e-001],\n",
              "       [1.11876377e+001, 2.42166567e+000],\n",
              "       [4.34003030e-013, 3.38225354e+000],\n",
              "       [1.00150262e+001, 1.39901174e-003],\n",
              "       [1.70328480e-082, 5.31147232e+000],\n",
              "       [1.67771253e-050, 1.29954148e+001],\n",
              "       [3.69626035e-088, 1.42952926e+000],\n",
              "       [2.36971714e+001, 1.79199785e-003],\n",
              "       [2.60854832e-080, 6.57496921e+000],\n",
              "       [3.52770539e+001, 2.83908422e-001],\n",
              "       [2.48865517e+001, 9.29298360e-001],\n",
              "       [6.44427691e-069, 6.33570495e+000],\n",
              "       [2.79658912e+001, 1.75304171e+000],\n",
              "       [9.76966481e-007, 2.01744652e+000],\n",
              "       [2.02315121e+001, 1.19730001e-001],\n",
              "       [1.50479927e+001, 4.11019156e-006],\n",
              "       [1.21877801e-049, 1.13805396e+001],\n",
              "       [2.78282403e+001, 7.42580581e-001],\n",
              "       [1.84490503e-008, 5.74549045e+000],\n",
              "       [9.14370797e-049, 1.80467004e+000],\n",
              "       [7.67489716e+000, 4.91397731e-006],\n",
              "       [9.81898773e-154, 1.08775701e+000],\n",
              "       [2.05755010e-032, 3.68529174e+000],\n",
              "       [6.33270996e+000, 4.84062814e-010],\n",
              "       [1.57637933e+001, 3.45192993e-001],\n",
              "       [8.54318285e+000, 1.28546700e-011],\n",
              "       [1.85165426e-114, 1.37852275e+000],\n",
              "       [9.96410935e+000, 1.20422556e-002],\n",
              "       [1.66465710e+001, 1.12685095e-004],\n",
              "       [1.39157729e-011, 5.53538998e+000],\n",
              "       [1.15312156e-045, 1.56081333e+000],\n",
              "       [9.45366478e+000, 8.31561761e-007],\n",
              "       [2.28665156e+001, 1.31000059e-004],\n",
              "       [1.56083562e+001, 1.54166506e-009],\n",
              "       [1.93448102e-006, 3.84543147e-002],\n",
              "       [2.16456068e-036, 9.53313035e+000],\n",
              "       [7.30680171e-012, 9.81154644e+000],\n",
              "       [3.30204417e-013, 9.31964787e+000],\n",
              "       [3.99179530e-090, 3.89699063e+000],\n",
              "       [1.86835383e-015, 2.97356440e+000],\n",
              "       [1.44743044e-017, 1.00263876e+001],\n",
              "       [1.46601601e+001, 3.94107551e-001],\n",
              "       [1.83863367e-012, 1.30723639e+001],\n",
              "       [9.98517958e-029, 1.02120036e+001],\n",
              "       [2.32002946e-120, 6.68734897e-001],\n",
              "       [1.35192803e+000, 4.20793034e-007],\n",
              "       [2.27074232e+000, 2.77811357e-005],\n",
              "       [4.63309461e-044, 4.81469716e+000],\n",
              "       [8.78085298e-026, 1.20893788e+001],\n",
              "       [1.93334044e+001, 5.64614856e-007],\n",
              "       [3.83673903e+001, 4.44593879e-002],\n",
              "       [1.70017171e+001, 3.68662464e-001],\n",
              "       [2.41176099e-005, 9.29523667e+000],\n",
              "       [2.03726481e-068, 6.68177716e+000],\n",
              "       [3.08325159e-104, 5.86013242e+000],\n",
              "       [4.41981525e+000, 4.94652477e-003],\n",
              "       [1.93857254e+001, 5.28140478e-007],\n",
              "       [1.00096237e+001, 2.47908070e-002],\n",
              "       [1.02787665e-039, 8.60521742e+000],\n",
              "       [1.69901186e-017, 1.41386650e+001],\n",
              "       [2.78929036e-002, 3.81548376e+000],\n",
              "       [3.60243198e+000, 2.79630575e-010],\n",
              "       [3.11787039e+001, 9.52935699e-004],\n",
              "       [6.78254883e+000, 9.29872178e-008],\n",
              "       [2.07970270e+000, 2.30879112e+000],\n",
              "       [1.98329409e+001, 7.36532520e-002],\n",
              "       [2.19348498e-217, 2.80699187e-003],\n",
              "       [1.55829024e+001, 1.60734768e-001],\n",
              "       [1.15556127e+001, 1.87577198e-005],\n",
              "       [9.66720639e-001, 6.55635240e-004],\n",
              "       [2.40865869e+001, 1.38082421e-001],\n",
              "       [3.39240747e-035, 1.10679723e+001],\n",
              "       [3.03003800e+000, 2.35451060e-005],\n",
              "       [4.23937188e+000, 5.00827490e-003],\n",
              "       [4.80265908e-087, 5.95430980e-001],\n",
              "       [1.43714268e-035, 7.59914265e+000],\n",
              "       [4.36368958e+000, 2.87215713e-002],\n",
              "       [1.01602644e-023, 4.83450004e+000],\n",
              "       [1.16054873e+001, 1.42826458e-003],\n",
              "       [9.90148918e+000, 9.28701373e-003],\n",
              "       [1.69654467e+001, 2.59958848e+000],\n",
              "       [2.84347300e-059, 6.22601723e+000],\n",
              "       [3.28559524e-031, 6.41566437e+000],\n",
              "       [4.66562593e-012, 8.20095673e+000],\n",
              "       [1.86740848e+001, 1.11137630e-005],\n",
              "       [3.81774425e+000, 7.02702105e-001],\n",
              "       [7.14500545e-052, 1.38180344e+001],\n",
              "       [4.08815003e-058, 5.07198631e+000],\n",
              "       [1.50460667e+001, 1.38363595e-004],\n",
              "       [1.84244024e+001, 3.22656394e+000],\n",
              "       [2.62247989e-072, 7.95210955e+000],\n",
              "       [4.35753293e-017, 1.17111873e+001],\n",
              "       [1.04529043e+000, 1.36568157e+000],\n",
              "       [2.84143653e+001, 8.02759221e-002],\n",
              "       [2.11269266e-045, 1.46903696e+001],\n",
              "       [1.37957063e+001, 1.00215278e-001],\n",
              "       [4.69028216e-045, 1.18736387e+000],\n",
              "       [1.78170722e-033, 8.76486651e+000],\n",
              "       [2.17224602e+001, 9.95942299e-006]])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypreds= model.predict(X_test)\n",
        "ypreds\n"
      ],
      "metadata": {
        "id": "D4clV6PK1UJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10f976f-0fbf-42d1-d740-c2242110ff68"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy(y_test, ypreds)"
      ],
      "metadata": {
        "id": "QgG1xPUg1ULw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64efb752-ba25-435e-c882-1f3272004d9e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.5"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Models Regression**"
      ],
      "metadata": {
        "id": "A-iFB_Z4voT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import STRING\n",
        "class LogisticRegression:\n",
        "  '''\n",
        "  The goal of this class is to create a LogisticRegression class, \n",
        "  that we will use as our model to classify data point into a corresponding class\n",
        "  '''\n",
        "  def __init__(self,lr,n_epochs):\n",
        "    self.lr = lr\n",
        "    self.n_epochs = n_epochs\n",
        "    self.train_losses = []\n",
        "    self.w = None\n",
        "    self.weight = []\n",
        "    self.num_iters = 10000\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "   \n",
        "    one = np.ones((x.shape[0],1))\n",
        "   \n",
        "    return np.hstack((one,x))\n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    ##### WRITE YOUR CODE HERE ####\n",
        "     \n",
        "     return 1/(1+np.exp(-x@self.w))\n",
        "    #### END CODE ####\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    y_pred = self.sigmoid(x)\n",
        "    loss = - np.mean(y_true* np.log(y_pred) +(1-y_true)* np.log(1- y_pred))\n",
        "    return loss\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x)\n",
        "    proba = self.sigmoid(x)\n",
        "    return proba\n",
        "    #### END CODE ####\n",
        "\n",
        "  def predict(self,x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    probas = self.predict_proba(x)\n",
        "    #treshold=0.5\n",
        "    output = [0 if p<0.5 else 1 for p in  probas]\n",
        "    return output\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    # Add ones to x\n",
        "    x= self.add_ones(x)\n",
        "    # reshape y if needed\n",
        "    y= y.reshape(-1,1)\n",
        "\n",
        "    # Initialize w to zeros vector >>> (x.shape[1])\n",
        "    \n",
        "    self.w = np.zeros((x.shape[1], 1))\n",
        "    for epoch in range(self.n_epochs):\n",
        "      # make predictions\n",
        "      ypred = self.sigmoid(x)\n",
        "\n",
        "      #compute the gradient\n",
        "      dl = (-1/x.shape[0])*(x.T@(y-ypred))\n",
        "      #update rule\n",
        "      self.w = self.w -  self.lr*dl\n",
        "\n",
        "      #Compute and append the training loss in a list\n",
        "      loss = self.cross_entropy(x,y)\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "      # if epoch%100 == 0:\n",
        "      #   print(f'loss for epoch {epoch}  : {loss}')\n",
        "\n",
        "  def accuracy(self,y_true, y_pred):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    acc = np.mean(y_pred ==y_true)*100\n",
        "    return acc\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "OpXYY-yj1UOj"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(0.01,n_epochs=10000)\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "k1YIYUGPv_2k"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_train = model.predict(X_train)\n",
        "acc = model.accuracy(y_train,ypred_train)\n",
        "print(f\"The training accuracy is: {acc}\")\n",
        "print(\" \")\n",
        "\n",
        "ypred_test = model.predict(X_test)\n",
        "acc = model.accuracy(y_test,ypred_test)\n",
        "print(f\"The test accuracy is: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khck3AcJwELo",
        "outputId": "5f5bcc01-7bf1-4528-fa29-8ff6d4e94adc"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: 94.75\n",
            " \n",
            "The test accuracy is: 94.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sEEwCJ9bw9OQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}